{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f57f338",
   "metadata": {},
   "source": [
    "## 1. Math (3 points): Demostración del Teorema de Frisch-Waugh-Lovell (FWL)\n",
    "\n",
    "[cite_start]El objetivo es probar que el estimador de Mínimos Cuadrados Ordinarios (MCO) para $\\theta_1$ en el modelo de regresión lineal completo es idéntico al estimador obtenido a través del procedimiento de dos pasos descrito[cite: 32, 33].\n",
    "\n",
    "### El Modelo de Regresión Completo\n",
    "\n",
    "[cite_start] Consideremos el modelo de regresión lineal[cite: 31]:\n",
    "$$y = X_1\\theta_1 + X_2\\theta_2 + \\epsilon$$\n",
    "Donde:\n",
    "* [cite_start]$y$ es el vector de resultados[cite: 28].\n",
    "* [cite_start]$X_1$ es la matriz de regresores de interés[cite: 29].\n",
    "* [cite_start]$X_2$ es la matriz de variables de control[cite: 30].\n",
    "\n",
    "Utilizando la fórmula para una matriz inversa particionada, se puede demostrar que el estimador MCO para $\\theta_1$ es:\n",
    "$$\\hat{\\theta}_1 = (X_1'M_2X_1)^{-1}(X_1'M_2y)$$\n",
    "Donde $M_2 = I - X_2(X_2'X_2)^{-1}X_2'$ es la **matriz de proyección residual** (o **matriz aniquiladora**) para $X_2$. Esta matriz es **simétrica** ($M_2' = M_2$) e **idempotente** ($M_2M_2 = M_2$).\n",
    "\n",
    "### El Procedimiento por Pasos\n",
    "\n",
    "Ahora, aplicamos el procedimiento descrito.\n",
    "\n",
    "**1. Obtener los residuos $\\hat{y}_1$**\n",
    "\n",
    "[cite_start]Regresamos $y$ en $X_2$ y obtenemos los residuos[cite: 34]. El vector de coeficientes para esta regresión es $\\hat{\\beta}_y = (X_2'X_2)^{-1}X_2'y$. Los residuos, que el problema llama $\\hat{y}_1$, son:\n",
    "$$\\hat{y}_1 = y - X_2\\hat{\\beta}_y = y - X_2(X_2'X_2)^{-1}X_2'y$$\n",
    "Factorizando $y$, obtenemos:\n",
    "$$\\hat{y}_1 = (I - X_2(X_2'X_2)^{-1}X_2')y = M_2y$$\n",
    "\n",
    "**2. Obtener los residuos $\\hat{X}_1$**\n",
    "\n",
    "[cite_start]De forma análoga, regresamos cada columna de la matriz $X_1$ en $X_2$ y obtenemos la matriz de residuos[cite: 35]. La matriz de residuos $\\hat{X}_1$ es:\n",
    "$$\\hat{X}_1 = X_1 - X_2(X_2'X_2)^{-1}X_2'X_1$$\n",
    "Factorizando $X_1$, obtenemos:\n",
    "$$\\hat{X}_1 = (I - X_2(X_2'X_2)^{-1}X_2')X_1 = M_2X_1$$\n",
    "\n",
    "### La Regresión Final y la Prueba Formal\n",
    "\n",
    "[cite_start]Finalmente, regresamos los residuos $\\hat{y}_1$ en los residuos $\\hat{X}_1$[cite: 37]. El estimador MCO para esta regresión es, por definición:\n",
    "$$\\hat{\\theta}_{1,FWL} = (\\hat{X}_1'\\hat{X}_1)^{-1}\\hat{X}_1'\\hat{y}_1$$\n",
    "Sustituimos las definiciones de $\\hat{X}_1$ y $\\hat{y}_1$:\n",
    "$$\\hat{\\theta}_{1,FWL} = ((M_2X_1)'(M_2X_1))^{-1}((M_2X_1)'(M_2y))$$\n",
    "Usando las propiedades de simetría e idempotencia de $M_2$:\n",
    "* $(\\hat{X}_1'\\hat{X}_1) = (M_2X_1)'(M_2X_1) = X_1'M_2'M_2X_1 = X_1'M_2X_1$\n",
    "* $(\\hat{X}_1'\\hat{y}_1) = (M_2X_1)'(M_2y) = X_1'M_2'M_2y = X_1'M_2y$\n",
    "\n",
    "Sustituyendo estos resultados simplificados de vuelta en la fórmula:\n",
    "$$\\hat{\\theta}_{1,FWL} = (X_1'M_2X_1)^{-1}(X_1'M_2y)$$\n",
    "Esta expresión es **exactamente la misma** que la fórmula para $\\hat{\\theta}_1$ de la regresión completa. [cite_start]Con esto, hemos demostrado formalmente lo que se pedía[cite: 38]:\n",
    "$$\\hat{\\theta}_{1}=(\\hat{X}_{1}'\\hat{X}_{1})^{-1}\\hat{X}_{1}'\\hat{y}_{1}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021d750",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
